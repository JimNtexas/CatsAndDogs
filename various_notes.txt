#alternate using torch.flatten and other notes

def convs(self, x):

        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))

        x = F.max_pool2d(F.relu(self.conv2(x)), (2,2))

        x = F.max_pool2d(F.relu(self.conv3(x)), (2,2))

        x = torch.flatten(x, 1, -1)

        if self._to_linear is None:
            self._to_linear = x.shape[1]

        return x


    def forward(self, x):

        x = self.convs(x)

        x = F.relu(self.fc1(x))

        x = self.fc2(x)

        return F.softmax(x, dim=1)


-----
check out:  https://jhui.github.io/2018/02/09/PyTorch-neural-networks/